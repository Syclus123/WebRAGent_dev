"""
Single task evaluation scripts are supported
Observation and planning of operator patterns are supported

Usage:
    xvfb-run -a python eval_op.py --observation_mode operator --global_reward_mode dom_reward --global_reward_text_model gpt-4o-mini --planning_text_model computer-use-preview-2025-03-11 --single_task_name "Find discussions of the community and open one with the most replies on Flightaware." --single_task_website "https://www.flightaware.com/" --rag_logging_enabled --rag_log_dir test/exp4/rag_logs
"""

from agent.Environment.html_env.async_env import AsyncHTMLEnvironment
from agent.Environment.html_env.operator_env import OperatorEnvironment
from agent.Environment.html_env.operator_actions import OperatorResponseParser, OperatorActionFactory
from evaluate import *
from agent.Plan import *
from dataclasses import dataclass

import re
import asyncio
import argparse
import logging
import json
import time
import os

# universal tools
from agent.Utils.utils import *
# evaluate tools
from evaluate.evaluate_utils import run_task, read_config, read_file
from agent.Utils.utils import read_json_file
from experiment_results import get_evaluate_result

logger = logging.getLogger(__name__)

from agent.LLM.token_utils import is_model_supported


@dataclass
class ExperimentConfig:
    mode: str
    global_reward_mode: str
    planning_text_model: str
    global_reward_text_model: str
    ground_truth_mode: bool
    single_task_name: str
    config: dict
    ground_truth_data: dict
    write_result_file_path: str
    record_time: str
    file: list
    rag_enabled: bool
    rag_path: str
    screenshot_base_dir: str
    rag_logging_enabled: bool
    rag_log_dir: str
    rag_mode: str

def validate_config(config, observation_mode, global_reward_mode, observation_model, global_reward_model):
    """
    Validate configuration, operator mode is supported
    """
    task_mode = config['basic']['task_mode']
    batch_tasks_file_path = config['files']['batch_tasks_file_path']
    json_model_response = config['model']['json_model_response']
    all_json_models = config['model']['json_models']
    interaction_mode = config['steps']['interaction_mode']

    # operator observation mode
    if observation_mode not in ["dom", "operator", "vision", "dom_v_desc", "vision_to_dom", "d_v"]:
        logger.error(
            f"observation mode '{observation_mode}' is not supported! "
            f"Supported modes: dom, operator, vision, dom_v_desc, vision_to_dom, d_v")
        exit()

    if interaction_mode not in [True, False]:
        logger.error(
            "interaction_mode is not defined! Try to define whether you want to evaluate the agent in an interactive manner.")
        exit()

    # json mode
    if observation_mode == "operator":
        logger.info("Using operator mode - JSON mode validation adjusted for operator models")
        if json_model_response:
            if "operator" in observation_model or "computer-use-preview" in observation_model:
                logger.info("Operator model detected - JSON mode will be handled specially")
            elif observation_model not in all_json_models:
                logger.error("Model does not support JSON mode!")
                exit()
    else:
        # Original validation logic
        if json_model_response and (observation_model not in all_json_models or (
                global_reward_mode != 'no_global_reward' and global_reward_model not in all_json_models)):
            logger.error("Model does not support JSON mode!")
            exit()

    if task_mode == 'batch_tasks' and not os.path.exists(batch_tasks_file_path):
        logger.error("batch_tasks_file_path not exist!")
        exit()


def get_task_range(task_mode, file, raw_data_index):
    if task_mode == "batch_tasks":
        if raw_data_index != -1:
            re_result = re.split(r'\s|,', raw_data_index)
            raw_data_start_index = int(re_result[0])
            raw_data_end_index = int(re_result[-1]) + 1
        else:
            raw_data_start_index = 0
            raw_data_end_index = len(file)
        return range(raw_data_start_index, raw_data_end_index)
    elif task_mode == "single_task":
        return range(0, 1)
    else:
        logger.error("task_mode error!")
        exit()


def log_task_info(task_index, task_name, reference_task_length, reference_evaluate_steps):
    logger.info("*" * 100)
    logger.info(f"task index: {task_index}")
    logger.info(f"task name: {task_name}")
    logger.info(f"task reference length: {reference_task_length}")
    logger.info(f"raw data annotation: {reference_evaluate_steps}")


def generate_result_file_path(config):
    return os.path.join(config["files"]["out_file_path"], "json_result")


def load_ground_truth_data(config, ground_truth_mode):
    if ground_truth_mode:
        ground_truth_file_path = config['files']['ground_truth_file_path']
        if not os.path.exists(ground_truth_file_path):
            logger.error("ground_truth_file_path not exist!")
            exit()
        return read_json_file(ground_truth_file_path)
    return None


def create_html_environment(mode, screenshot_dir="screenshots_operator"):
    """
    åˆ›å»ºHTMLç¯å¢ƒï¼Œé’ˆå¯¹operatoræ¨¡å¼ä¼˜åŒ–
    """
    if mode == "operator":
        # ä½¿ç”¨ä¸“é—¨çš„OperatorEnvironment
        return OperatorEnvironment(
            headless=True,  # ç¡®ä¿åœ¨æœåŠ¡å™¨ç¯å¢ƒä¸­ä½¿ç”¨æ— å¤´æ¨¡å¼
            slow_mo=50,     # ä¿®å¤ï¼šå‡å°‘å»¶è¿Ÿæ—¶é—´ï¼Œæé«˜å“åº”é€Ÿåº¦
            viewport_width=1280,
            viewport_height=720,
            save_trace_enabled=True,
            screenshot_dir=screenshot_dir
        )
    else:
        # å…¶ä»–æ¨¡å¼ä½¿ç”¨åŸæœ‰é…ç½®
        return AsyncHTMLEnvironment(
            mode=mode,
            max_page_length=8192,
            headless=False,
            slow_mo=1000,
            current_viewport_only=False,
            viewport_size={"width": 1080, "height": 720},
            save_trace_enabled=True,
            sleep_after_execution=0.0,
            locale="en-US",
            use_vimium_effect=True
        )


async def run_operator_task(env, task_name, task_uuid, website, config, 
                          planning_text_model, record_time, write_result_file_path,
                          reference_task_length, reference_evaluate_steps, 
                          screenshot_params, rag_enabled, rag_path, global_reward_mode="no_global_reward", 
                          global_reward_text_model="gpt-4o-mini", ground_truth_mode=False, ground_truth_data=None,
                          rag_logging_enabled=False, rag_log_dir=None, rag_mode="description"):
    """
    è¿è¡Œoperatorä»»åŠ¡ (æ”¯æŒDOM rewardå’Œæ™ºèƒ½åœæ­¢)
    """
    logger.info(f"ğŸš€ Starting operator task: {task_name}")
    logger.info(f"ğŸ“± Model: {planning_text_model}")
    logger.info(f"ğŸŒ Website: {website}")
    logger.info(f"ğŸ† Reward mode: {global_reward_mode}")
    logger.info(f"ğŸ§  RAG mode: {rag_mode}")
    logger.info(f"ğŸ“ RAG logging: {'Enabled' if rag_logging_enabled else 'Disabled'}")
    
    # RAG Logger
    rag_logger = None
    if rag_logging_enabled:
        if rag_mode == "vision":
            from agent.Utils.rag_logger import VisionRAGLogger
            rag_logger = VisionRAGLogger(rag_log_dir=rag_log_dir)
            actual_rag_dir = rag_logger.vision_rag_dir
            logger.info(f"ğŸ“‚ Vision RAG logs will be saved to: {actual_rag_dir}")
        else:
            from agent.Utils.rag_logger import RAGLogger
            rag_logger = RAGLogger(rag_log_dir=rag_log_dir)
            actual_rag_dir = rag_logger.rag_dir
            logger.info(f"ğŸ“‚ RAG logs will be saved to: {actual_rag_dir}")
    
    # å¯åŠ¨ç¯å¢ƒ
    await env.start()
    
    try:
        # ç½‘ç»œæ£€æŸ¥
        logger.info("ğŸ” Performing network health check...")
        network_healthy = await env.check_network_health(website)
        if not network_healthy:
            logger.warning("âš ï¸  Network health check failed, but proceeding with caution...")
        
        await env.navigate_to(website)
        
        # åˆå§‹åŒ–æˆªå›¾å˜é‡
        # current_screenshot = await env.take_screenshot("initial.png")
        current_screenshot = ""
        
        from agent.LLM.llm_instance import create_llm_instance
        
        operator_model = create_llm_instance(
            model=planning_text_model,
            json_mode=False
        )
        
        # OperatorMode
        from agent.Plan.planning import OperatorMode
        operator_mode = OperatorMode(text_model=operator_model)
        
        # ä»»åŠ¡æ‰§è¡Œå¾ªç¯(æ”¯æŒåŠ¨æ€æ­¥æ•°)
        max_steps = config.get('steps', {}).get('operator_max_steps', 50)  # å¢åŠ æœ€å¤§æ­¥æ•°é™åˆ¶
        logger.info(f"ğŸ“Š Using dynamic step limit with maximum: {max_steps}")
        
        step_count = 0
        previous_trace = [] 
        feedback = ""
        status_description = f"Starting task: {task_name}"
        
        task_trace = []
        
        # æ·»åŠ çŠ¶æ€è·Ÿè¸ªï¼Œé¿å…é‡å¤æ— æ•ˆæ“ä½œ
        consecutive_failed_scrolls = 0
        last_action_type = None
        
        # DOM reward
        task_finished = False
        task_global_status = ""
        total_reward_score = 0
        consecutive_low_scores = 0  # è¿ç»­ä½åˆ†è®¡æ•°
        
        # è·å–åˆå§‹DOMè§‚å¯Ÿ
        if hasattr(env, 'get_obs'):
            # å¯¹äºoperatorç¯å¢ƒï¼Œéœ€è¦æ¨¡æ‹ŸDOMè§‚å¯Ÿ
            try:
                # è·å–é¡µé¢æ ‡é¢˜å’ŒURLä½œä¸ºåŸºæœ¬è§‚å¯Ÿä¿¡æ¯
                page_title = await env.page.title()
                page_url = env.page.url
                observation = f"current web tab name is '{page_title}'\nURL: {page_url}"
            except Exception:
                observation = "Page observation not available"
        else:
            observation = "Operator mode - visual observation only"
        
        logger.info(f"ğŸ”„ Starting operator task loop with reward-based stopping...")
        
        while step_count < max_steps:
            logger.info(f"ğŸ“¸ Step {step_count + 1} (max: {max_steps})")
            
            # æ¯ä¸ªæ­¥éª¤éƒ½ä¿å­˜æˆªå›¾ï¼ˆç§»é™¤å»é‡æœºåˆ¶ï¼‰
            screenshot_filename = f"step_{step_count:03d}.png"
            
            # ç¡®ä¿é¡µé¢å‡†å¤‡å¥½è¿›è¡Œæˆªå›¾
            await ensure_page_ready_for_screenshot(env)
            
            # è·å–å½“å‰æˆªå›¾
            current_screenshot = await env.take_screenshot(screenshot_filename)
            logger.info(f"ğŸ“· Screenshot taken: {screenshot_filename}")
            
            # DOM Rewardè¯„ä¼° (åœ¨planningä¹‹å‰è¿›è¡Œï¼ŒåŸºäºprevious trace)
            step_reward = {}
            reward_token_count = [0, 0]
            
            if global_reward_mode != 'no_global_reward' and len(previous_trace) > 0:
                logger.info("ğŸ† Evaluating DOM reward...")
                try:
                    # æ›´æ–°è§‚å¯Ÿä¿¡æ¯
                    try:
                        page_title = await env.page.title()
                        page_url = env.page.url
                        observation = f"current web tab name is '{page_title}'\nURL: {page_url}"
                    except Exception:
                        observation = "Page observation not available"
                    
                    # å½“å‰ä¿¡æ¯
                    current_info = {"URL": env.page.url}
                    if "vision" in global_reward_mode:
                        current_info["vision_reward"] = current_screenshot
                    
                    # è°ƒç”¨GlobalRewardè¯„ä¼°
                    from agent.Reward.global_reward import GlobalReward
                    step_reward, reward_description, reward_token_count = await GlobalReward.evaluate(
                        config=config,
                        model_name=global_reward_text_model,
                        user_request=task_name,
                        previous_trace=previous_trace,
                        observation=observation,
                        current_info=current_info,
                        task_name_id=task_uuid,
                        global_reward_mode=global_reward_mode,
                        ground_truth_mode=ground_truth_mode,
                        ground_truth_data=ground_truth_data,
                    )
                    
                    if step_reward:
                        reward_score = int(step_reward.get("score", 0))
                        reward_status = step_reward.get("status", "doing")
                        total_reward_score += reward_score
                        
                        logger.info(f"ğŸ† Reward Score: {reward_score}/10")
                        logger.info(f"ğŸ“Š Status: {reward_status}")
                        logger.info(f"ğŸ’­ Reason: {step_reward.get('reason', 'No reason provided')}")
                        
                        # æ™ºèƒ½åœæ­¢åˆ¤æ–­
                        if reward_status == "finished" or reward_score == 10:
                            logger.info("ğŸ¯ Task completed based on reward evaluation!")
                            task_global_status = "finished"
                            task_finished = True
                            break
                        elif reward_status == "loop" or reward_score == 1:
                            consecutive_low_scores += 1
                            logger.warning(f"âš ï¸  Low score detected ({consecutive_low_scores}/3)")
                            if consecutive_low_scores >= 5:
                                logger.warning("ğŸ”„ Stopping due to consecutive low scores - task may be stuck")
                                task_global_status = "loop"
                                break
                        elif reward_score <= 3:
                            consecutive_low_scores += 1
                            if consecutive_low_scores >= 8:
                                logger.warning("ğŸ”„ Stopping due to persistent low performance")
                                task_global_status = "low_performance"
                                break
                        else:
                            consecutive_low_scores = 0  # é‡ç½®ä½åˆ†è®¡æ•°
                        
                        # æ›´æ–°çŠ¶æ€æè¿°
                        status_description = reward_description or f"Step {step_count + 1} - Score: {reward_score}"
                        
                except Exception as e:
                    logger.error(f"âŒ Error in reward evaluation: {e}")
                    step_reward = {}
            
            # æ‰§è¡Œplanning
            try:
                # å°†previous_traceè½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ç”¨äºoperator
                previous_trace_str = ""
                for i, trace in enumerate(previous_trace):
                    previous_trace_str += f"Step {i + 1}: {trace.get('thought', '')} -> {trace.get('action', '')}\n"
                
                planning_response, error_message, planning_response_thought, planning_response_action, planning_token_count, rag_data = await operator_mode.execute(
                    status_description=status_description,
                    user_request=task_name,
                    rag_enabled=rag_enabled,
                    rag_path=rag_path,
                    previous_trace=previous_trace_str,
                    observation="",  # operatoræ¨¡å¼ä¸éœ€è¦DOMè§‚å¯Ÿ
                    feedback=feedback,
                    observation_VforD=current_screenshot,
                    rag_mode=rag_mode
                )
                
                if error_message:
                    logger.error(f"Planning error: {error_message}")
                    break
                
                logger.info(f"Step Thought: {planning_response_thought}")
                logger.info(f"Step Action: {planning_response_action}")
                
                # RAG logger
                if rag_logging_enabled and rag_logger and rag_data:
                    try:
                        # æ·»åŠ é¢å¤–çš„æ­¥éª¤ä¿¡æ¯
                        rag_data.update({
                            "step_idx": step_count,
                            "task_name": task_name,
                            "website": website,
                            "model": planning_text_model,
                            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                            "planning_response": planning_response,
                            "planning_thought": planning_response_thought,
                            "planning_action": planning_response_action,
                            "feedback": feedback,
                            "status_description": status_description,
                            "token_count": planning_token_count,
                            "screenshot_filename": screenshot_filename
                        })
                        
                        rag_file_path = rag_logger.log_rag_step(task_uuid, step_count, rag_data)
                        logger.info(f"ğŸ“ RAG information logged to: {rag_file_path}")
                        
                    except Exception as rag_error:
                        logger.warning(f"âš ï¸  Failed to log RAG information: {rag_error}")
                
                # æ£€æµ‹æ˜¯å¦æ˜¯é‡å¤çš„æ— æ•ˆæ“ä½œ
                current_action_type = planning_response_action.get("action", "")
                
                # æ”¹è¿›çš„é‡å¤æ“ä½œæ£€æµ‹
                if is_repetitive_action(current_action_type, last_action_type, consecutive_failed_scrolls):
                    consecutive_failed_scrolls += 1
                    if consecutive_failed_scrolls >= 3:
                        logger.warning("âš ï¸  Detected repeated ineffective actions, trying alternative strategy")
                        feedback = "Previous actions seem ineffective. Try a different approach, look for alternative UI elements, or consider the task might be completed."
                        consecutive_failed_scrolls = 0
                        
                        # å°è¯•æ™ºèƒ½æ¢å¤ç­–ç•¥
                        alternative_action = await suggest_alternative_action(env, current_action_type, task_name)
                        if alternative_action:
                            planning_response_action = alternative_action
                            logger.info(f"ğŸ”„ Switching to alternative action: {alternative_action}")
                else:
                    consecutive_failed_scrolls = 0
                
                last_action_type = current_action_type
                
                # è®°å½•trace (åŒ…å«rewardä¿¡æ¯)
                trace_entry = {
                    "step": step_count,
                    "thought": planning_response_thought,
                    "action": planning_response_action,
                    "screenshot_taken": True, # æ¯ä¸ªæ­¥éª¤éƒ½æˆªå›¾
                    "screenshot": screenshot_filename,
                    "reward": step_reward,  # æ·»åŠ rewardä¿¡æ¯
                    "reward_tokens": reward_token_count
                }
                task_trace.append(trace_entry)
                
                # ä¸ºä¸‹ä¸€è½®rewardè¯„ä¼°å‡†å¤‡traceæ•°æ®
                current_trace = {
                    "thought": planning_response_thought,
                    "action": planning_response_action.get("action", ""),
                    "action_input": planning_response_action.get("action_input", ""),
                    "reflection": step_reward.get("description", "") if step_reward else ""
                }
                
                # æ‰§è¡Œaction
                success = await execute_operator_action(env, planning_response_action)
                
                if not success:
                    logger.error("Action execution failed")
                    feedback = "Action execution failed. Please try a different approach or simpler actions."
                    current_trace["reflection"] += " (Action execution failed)"
                else:
                    feedback = ""
                
                # æ·»åŠ åˆ°previous_traceç”¨äºä¸‹ä¸€è½®rewardè¯„ä¼°
                previous_trace.append(current_trace)
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if planning_response_action.get("action") == "get_final_answer":
                    logger.info("âœ… Task completed by final answer!")
                    task_finished = True
                    break
                
                step_count += 1
                
            except Exception as e:
                logger.error(f"Error in planning step: {e}")
                feedback = f"Error in planning: {str(e)}"
                break
        
        # è®¡ç®—æœ€ç»ˆçŠ¶æ€
        if task_finished:
            final_status = "finished"
        elif task_global_status == "finished":
            final_status = "llm_finished"
        elif task_global_status == "loop":
            final_status = "loop_detected"
        elif task_global_status == "low_performance":
            final_status = "low_performance"
        elif step_count >= max_steps:
            final_status = "step_limit"
        else:
            final_status = "unknown"
        
        result_data = {
            "task_name": task_name,
            "task_uuid": task_uuid,
            "model": planning_text_model,
            "website": website,
            "steps": step_count,
            "max_steps": max_steps,
            "final_status": final_status,
            "task_global_status": task_global_status,
            "total_reward_score": total_reward_score,
            "average_reward_score": total_reward_score / max(1, step_count),
            "reward_mode": global_reward_mode,
            "trace": task_trace,
            "final_state": await env.get_current_state(),
            "completed": task_finished or task_global_status == "finished",
            "record_time": record_time,
            "reward_based_stopping": global_reward_mode != 'no_global_reward'
        }
        
        result_file = os.path.join(write_result_file_path, f"{task_uuid}_{record_time}.json")
        os.makedirs(os.path.dirname(result_file), exist_ok=True)
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“ Result saved to: {result_file}")
        logger.info(f"ğŸ† Final Status: {final_status}")
        logger.info(f"ğŸ“Š Total Steps: {step_count}")
        logger.info(f"ğŸ¯ Total Reward Score: {total_reward_score}")
        if step_count > 0:
            logger.info(f"ğŸ“ˆ Average Reward Score: {total_reward_score / step_count:.2f}")
        
    except Exception as navigation_error:
        logger.error(f"âŒ Navigation failed: {navigation_error}")
        
        # å°è¯•æ¢å¤ç­–ç•¥
        logger.info("ğŸ”„ Attempting recovery strategies...")
        
        try:
            # ç­–ç•¥1ï¼šå°è¯•å¯¼èˆªåˆ°å¤‡ç”¨URLæˆ–ç®€å•é¡µé¢
            if "flightaware" in website.lower():
                backup_url = "https://www.google.com"
                logger.info(f"ğŸ”„ Trying backup URL: {backup_url}")
                await env.navigate_to(backup_url, max_retries=2)
                
                # ä»Googleæœç´¢ç›®æ ‡ç«™ç‚¹
                logger.info("ğŸ” Searching for target site from Google...")
                
            else:
                # å…¶ä»–ç«™ç‚¹çš„å¤‡ç”¨ç­–ç•¥
                logger.info("ğŸ”„ Using fallback navigation...")
                await env.navigate_to("about:blank")
                
        except Exception as recovery_error:
            logger.error(f"âŒ Recovery also failed: {recovery_error}")
            # ä¿å­˜é”™è¯¯ç»“æœ
            result_data = {
                "task_name": task_name,
                "task_uuid": task_uuid,
                "model": planning_text_model,
                "website": website,
                "error": "Navigation failed",
                "error_details": str(navigation_error),
                "recovery_error": str(recovery_error),
                "steps": 0,
                "max_steps": max_steps,
                "final_status": "navigation_error",
                "completed": False,
                "record_time": record_time,
                "reward_mode": global_reward_mode
            }
            
            # ä¿å­˜é”™è¯¯ç»“æœ
            result_file = os.path.join(write_result_file_path, f"{task_uuid}_{record_time}_error.json")
            os.makedirs(os.path.dirname(result_file), exist_ok=True)
            
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            logger.error(f"ğŸ’¾ Error result saved to: {result_file}")
            return  # é€€å‡ºä»»åŠ¡
        
        # å¦‚æœæ¢å¤æˆåŠŸï¼Œç»§ç»­ä»»åŠ¡
        logger.info("âœ… Recovery successful, continuing with task...")
        
        # é‡æ–°åˆå§‹åŒ–æˆªå›¾å’Œæ¨¡å‹
        current_screenshot = await env.take_screenshot()
        
        from agent.LLM.llm_instance import create_llm_instance
        
        operator_model = create_llm_instance(
            model=planning_text_model,
            json_mode=False
        )
        
        # åˆ›å»ºOperatorModeå®ä¾‹
        from agent.Plan.planning import OperatorMode
        operator_mode = OperatorMode(text_model=operator_model)
        
    finally:
        # å…³é—­ç¯å¢ƒ
        await env.close()


async def execute_operator_action(env, action_dict):
    """
    æ‰§è¡Œoperator action (ä¼˜åŒ–ç‰ˆæœ¬ - å‡å°‘ä¸å¿…è¦çš„waitæ“ä½œ)
    """
    action_type = action_dict.get("action", "wait")
    
    try:
        logger.info(f"ğŸ”§ Executing action: {action_type}")
        
        # è®°å½•æ“ä½œå‰çš„é¡µé¢çŠ¶æ€
        page_state_before = await get_page_state(env)
        
        if action_type == "operator_click":
            coords = action_dict.get("coordinates", [0, 0])
            logger.info(f"ğŸ“ Clicking at coordinates: {coords}")
            action = OperatorActionFactory.create_click_action(coords[0], coords[1])
            await env.execute_operator_actions([action])
            
            # ç‚¹å‡»åæ™ºèƒ½ç­‰å¾…é¡µé¢ç¨³å®š
            await wait_for_page_stability(env, expected_change=True)
            
        elif action_type == "operator_double_click":
            coords = action_dict.get("coordinates", [0, 0])
            logger.info(f"ğŸ“ Double-clicking at coordinates: {coords}")
            action = OperatorActionFactory.create_double_click_action(coords[0], coords[1])
            await env.execute_operator_actions([action])
            
            # åŒå‡»åæ™ºèƒ½ç­‰å¾…é¡µé¢ç¨³å®š
            await wait_for_page_stability(env, expected_change=True)
            
        elif action_type == "operator_type":
            text = action_dict.get("text", "")
            logger.info(f"âŒ¨ï¸  Typing text: '{text}'")
            action = OperatorActionFactory.create_type_action(text)
            await env.execute_operator_actions([action])
            
            # æ–‡æœ¬è¾“å…¥åçŸ­æš‚ç­‰å¾…ï¼ˆä¸éœ€è¦é•¿æ—¶é—´ç­‰å¾…ï¼‰
            await asyncio.sleep(0.3)
            
        elif action_type == "operator_scroll":
            scroll_x = action_dict.get("scroll_x", 0)
            scroll_y = action_dict.get("scroll_y", 0)
            
            # ä¿®å¤ï¼šå°†è¿‡å¤§çš„æ»šåŠ¨é‡è°ƒæ•´ä¸ºåˆç†èŒƒå›´
            if abs(scroll_y) > 500:
                scroll_y = 500 if scroll_y > 0 else -500
            if abs(scroll_x) > 500:
                scroll_x = 500 if scroll_x > 0 else -500
                
            logger.info(f"ğŸ“œ Scrolling: x={scroll_x}, y={scroll_y}")
            action = OperatorActionFactory.create_scroll_action(scroll_x, scroll_y)
            await env.execute_operator_actions([action])
            
            # æ»šåŠ¨åæ™ºèƒ½ç­‰å¾…å†…å®¹ç¨³å®š
            await wait_for_scroll_completion(env)
            
        elif action_type == "operator_keypress":
            keys = action_dict.get("keys", [])
            logger.info(f"ğŸ”‘ Pressing keys: {keys}")
            action = OperatorActionFactory.create_keypress_action(keys)
            await env.execute_operator_actions([action])
            
            # æŒ‰é”®åæ™ºèƒ½ç­‰å¾…ï¼ˆæŸäº›æŒ‰é”®å¯èƒ½è§¦å‘é¡µé¢å˜åŒ–ï¼‰
            if any(key.lower() in ['enter', 'return', 'tab'] for key in keys):
                await wait_for_page_stability(env, expected_change=True, timeout=3000)
            else:
                await asyncio.sleep(0.2)
            
        elif action_type == "operator_drag":
            path = action_dict.get("path", [[0, 0], [0, 0]])
            logger.info(f"ğŸ–±ï¸  Dragging from {path[0]} to {path[-1]}")
            action = OperatorActionFactory.create_drag_action(path)
            await env.execute_operator_actions([action])
            
            # æ‹–æ‹½åç­‰å¾…é¡µé¢ç¨³å®š
            await wait_for_page_stability(env, expected_change=True)
            
        elif action_type == "operator_wait":
            ms = action_dict.get("ms", 1000)
            # é™åˆ¶ç­‰å¾…æ—¶é—´åœ¨åˆç†èŒƒå›´å†…
            ms = min(ms, 5000)  # æœ€å¤šç­‰å¾…5ç§’
            logger.info(f"â³ Waiting for {ms}ms")
            action = OperatorActionFactory.create_wait_action(ms)
            await env.execute_operator_actions([action])
            
        elif action_type == "get_final_answer":
            logger.info(f"ğŸ¯ Task completion detected")
            # ä»»åŠ¡å®Œæˆï¼Œä¸éœ€è¦é¢å¤–ç­‰å¾…
            return True
            
        else:
            # ä¼˜åŒ–ï¼šå¯¹äºæœªçŸ¥æ“ä½œï¼Œä¸å†é»˜è®¤ç­‰å¾…ï¼Œè€Œæ˜¯å°è¯•è§£ææˆ–è·³è¿‡
            logger.warning(f"â“ Unknown action type '{action_type}', attempting minimal response")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ“ä½œæè¿°
            if "click" in action_type.lower():
                # å°è¯•è§£æä¸ºç‚¹å‡»æ“ä½œ
                coords = [640, 360]  # å±å¹•ä¸­å¿ƒä½œä¸ºé»˜è®¤ç‚¹å‡»ä½ç½®
                action = OperatorActionFactory.create_click_action(coords[0], coords[1])
                await env.execute_operator_actions([action])
                await wait_for_page_stability(env, expected_change=True)
            elif "scroll" in action_type.lower():
                # å°è¯•è§£æä¸ºæ»šåŠ¨æ“ä½œ
                action = OperatorActionFactory.create_scroll_action(0, 200)
                await env.execute_operator_actions([action])
                await wait_for_scroll_completion(env)
            else:
                # çœŸæ­£çš„æœªçŸ¥æ“ä½œï¼Œæœ€å°ç­‰å¾…
                logger.info(f"âš¡ Minimal wait for unknown action")
                await asyncio.sleep(0.5)  # å‡å°‘åˆ°0.5ç§’
        
        # æ£€æŸ¥é¡µé¢çŠ¶æ€å˜åŒ–
        page_state_after = await get_page_state(env)
        if page_state_changed(page_state_before, page_state_after):
            logger.info(f"ğŸ“„ Page state changed, ensuring stability...")
            await ensure_page_ready_for_screenshot(env)
        
        logger.info(f"âœ… Action '{action_type}' completed successfully")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Error executing operator action {action_type}: {e}")
        return False


async def get_page_state(env):
    """è·å–é¡µé¢çŠ¶æ€å¿«ç…§"""
    try:
        return {
            "url": env.page.url,
            "title": await env.page.title(),
            "scroll_position": await env.page.evaluate("window.pageYOffset"),
            "timestamp": time.time()
        }
    except Exception:
        return {"timestamp": time.time()}


def page_state_changed(state_before, state_after):
    """æ£€æŸ¥é¡µé¢çŠ¶æ€æ˜¯å¦å‘ç”Ÿå˜åŒ–"""
    if not state_before or not state_after:
        return True
    
    # æ£€æŸ¥URLå˜åŒ–
    if state_before.get("url") != state_after.get("url"):
        return True
    
    # æ£€æŸ¥æ ‡é¢˜å˜åŒ–
    if state_before.get("title") != state_after.get("title"):
        return True
    
    # æ£€æŸ¥æ»šåŠ¨ä½ç½®å˜åŒ–ï¼ˆè¶…è¿‡50åƒç´ è®¤ä¸ºæœ‰æ˜¾è‘—å˜åŒ–ï¼‰
    scroll_before = state_before.get("scroll_position", 0)
    scroll_after = state_after.get("scroll_position", 0)
    if abs(scroll_before - scroll_after) > 50:
        return True
    
    return False


async def wait_for_page_stability(env, expected_change=False, timeout=5000):
    """
    æ™ºèƒ½ç­‰å¾…é¡µé¢ç¨³å®š
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        expected_change: æ˜¯å¦æœŸæœ›é¡µé¢å‘ç”Ÿå˜åŒ–
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    """
    try:
        start_time = time.time()
        
        # ç­–ç•¥1ï¼šç­‰å¾…ç½‘ç»œè¯·æ±‚å®Œæˆ
        try:
            await env.page.wait_for_load_state("networkidle", timeout=min(3000, timeout))
            logger.info("âœ… Network idle achieved")
            return
        except Exception:
            logger.debug("Network idle timeout, trying alternative strategies...")
        
        # ç­–ç•¥2ï¼šç­‰å¾…DOMç¨³å®š
        stable_count = 0
        last_dom_size = 0
        
        while (time.time() - start_time) * 1000 < timeout:
            try:
                # æ£€æŸ¥DOMå¤§å°
                dom_size = await env.page.evaluate("document.documentElement.innerHTML.length")
                
                if dom_size == last_dom_size:
                    stable_count += 1
                    if stable_count >= 3:  # è¿ç»­3æ¬¡æ£€æŸ¥DOMå¤§å°ç›¸åŒï¼Œè®¤ä¸ºç¨³å®š
                        logger.info("âœ… DOM stability achieved")
                        return
                else:
                    stable_count = 0
                    last_dom_size = dom_size
                
                await asyncio.sleep(0.5)
                
            except Exception:
                break
        
        # ç­–ç•¥3ï¼šåŸºç¡€ç­‰å¾…
        logger.debug("Using fallback wait strategy")
        await asyncio.sleep(1)
        
    except Exception as e:
        logger.warning(f"Page stability check failed: {e}")


async def wait_for_scroll_completion(env):
    """ç­‰å¾…æ»šåŠ¨æ“ä½œå®Œæˆ"""
    try:
        # ç­‰å¾…æ»šåŠ¨åŠ¨ç”»å®Œæˆ
        last_scroll = -1
        stable_count = 0
        
        for _ in range(10):  # æœ€å¤šæ£€æŸ¥10æ¬¡
            current_scroll = await env.page.evaluate("window.pageYOffset")
            
            if current_scroll == last_scroll:
                stable_count += 1
                if stable_count >= 2:  # è¿ç»­2æ¬¡ä½ç½®ç›¸åŒï¼Œè®¤ä¸ºæ»šåŠ¨å®Œæˆ
                    logger.info("âœ… Scroll completion detected")
                    return
            else:
                stable_count = 0
                last_scroll = current_scroll
            
            await asyncio.sleep(0.2)
        
        logger.info("âœ… Scroll timeout reached, assuming completion")
        
    except Exception as e:
        logger.warning(f"Scroll completion check failed: {e}")


async def ensure_page_ready_for_screenshot(env):
    """ç¡®ä¿é¡µé¢å·²å‡†å¤‡å¥½è¿›è¡Œæˆªå›¾"""
    try:
        # ç­‰å¾…æ¸²æŸ“å®Œæˆ
        await env.page.wait_for_timeout(500)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰åŠ è½½æŒ‡ç¤ºå™¨
        try:
            loading_indicators = await env.page.evaluate("""
                () => {
                    const indicators = [
                        'div[class*="loading"]',
                        'div[class*="spinner"]',
                        'div[class*="loader"]',
                        '.loading',
                        '.spinner',
                        '.loader'
                    ];
                    
                    for (const selector of indicators) {
                        const elements = document.querySelectorAll(selector);
                        for (const el of elements) {
                            const style = window.getComputedStyle(el);
                            if (style.display !== 'none' && style.visibility !== 'hidden') {
                                return true;
                            }
                        }
                    }
                    return false;
                }
            """)
            
            if loading_indicators:
                logger.info("â³ Waiting for loading indicators to disappear...")
                # ç­‰å¾…åŠ è½½æŒ‡ç¤ºå™¨æ¶ˆå¤±
                for _ in range(10):
                    await asyncio.sleep(0.5)
                    still_loading = await env.page.evaluate("""
                        () => {
                            const indicators = [
                                'div[class*="loading"]',
                                'div[class*="spinner"]', 
                                'div[class*="loader"]',
                                '.loading',
                                '.spinner',
                                '.loader'
                            ];
                            
                            for (const selector of indicators) {
                                const elements = document.querySelectorAll(selector);
                                for (const el of elements) {
                                    const style = window.getComputedStyle(el);
                                    if (style.display !== 'none' && style.visibility !== 'hidden') {
                                        return true;
                                    }
                                }
                            }
                            return false;
                        }
                    """)
                    
                    if not still_loading:
                        logger.info("âœ… Loading indicators disappeared")
                        break
            
            logger.info("âœ… Page ready for screenshot")
            
        except Exception:
            logger.debug("Loading indicator check failed, proceeding anyway")
            
    except Exception as e:
        logger.warning(f"Page readiness check failed: {e}")


async def get_page_signature(env):
    """
    è·å–é¡µé¢ç­¾åï¼Œç”¨äºæ£€æµ‹é¡µé¢æ˜¯å¦å‘ç”Ÿå®è´¨æ€§å˜åŒ–
    """
    try:
        signature_data = await env.page.evaluate("""
            () => {
                try {
                    // è·å–é¡µé¢çš„å…³é”®ç‰¹å¾
                    const url = window.location.href;
                    const title = document.title;
                    const scrollPosition = window.pageYOffset;
                    const visibleText = document.body ? document.body.innerText.substring(0, 500) : ''; // å‰500å­—ç¬¦
                    const elementCount = document.querySelectorAll('*').length;
                    
                    // è·å–ä¸»è¦å†…å®¹åŒºåŸŸçš„ç‰¹å¾
                    const mainContent = document.querySelector('main, #main, .main, #content, .content, .container');
                    const mainText = mainContent ? mainContent.innerText.substring(0, 200) : '';
                    
                    // å®‰å…¨çš„æ–‡æœ¬å“ˆå¸Œå‡½æ•°ï¼Œé¿å…btoaç¼–ç é—®é¢˜
                    function safeHash(text) {
                        if (!text) return '';
                        
                        try {
                            // ç®€å•çš„å­—ç¬¦ä¸²å“ˆå¸Œå‡½æ•°
                            let hash = 0;
                            for (let i = 0; i < text.length; i++) {
                                const char = text.charCodeAt(i);
                                hash = ((hash << 5) - hash) + char;
                                hash = hash & hash; // è½¬æ¢ä¸º32ä½æ•´æ•°
                            }
                            return hash.toString(36); // è½¬æ¢ä¸º36è¿›åˆ¶å­—ç¬¦ä¸²
                        } catch (e) {
                            console.warn('Text hashing failed:', e);
                            return text.length.toString(); // å¤‡ç”¨ï¼šè¿”å›æ–‡æœ¬é•¿åº¦
                        }
                    }
                    
                    return {
                        url: url || '',
                        title: title || '',
                        scrollPosition: Math.floor(scrollPosition / 100) * 100, // é‡åŒ–æ»šåŠ¨ä½ç½®ï¼Œå‡å°‘å°å¹…æ»šåŠ¨çš„å½±å“
                        visibleTextHash: safeHash(visibleText), // ä½¿ç”¨å®‰å…¨çš„å“ˆå¸Œå‡½æ•°
                        elementCount: elementCount || 0,
                        mainTextHash: safeHash(mainText)
                    };
                } catch (error) {
                    console.error('Page signature generation failed:', error);
                    // è¿”å›æœ€åŸºæœ¬çš„ç­¾åæ•°æ®
                    return {
                        url: window.location.href || '',
                        title: document.title || '',
                        scrollPosition: 0,
                        visibleTextHash: 'error',
                        elementCount: 0,
                        mainTextHash: 'error'
                    };
                }
            }
        """)
        
        # éªŒè¯ç­¾åæ•°æ®çš„å®Œæ•´æ€§
        if not signature_data:
            logger.warning("Page signature data is empty, using fallback")
            signature_data = {
                'url': 'unknown',
                'title': 'unknown', 
                'scrollPosition': 0,
                'visibleTextHash': 'fallback',
                'elementCount': 0,
                'mainTextHash': 'fallback'
            }
        
        # åˆ›å»ºé¡µé¢ç­¾å
        import hashlib
        signature_string = f"{signature_data['url']}|{signature_data['title']}|{signature_data['scrollPosition']}|{signature_data['visibleTextHash']}|{signature_data['elementCount']}|{signature_data['mainTextHash']}"
        signature_hash = hashlib.md5(signature_string.encode('utf-8')).hexdigest()
        
        logger.debug(f"Page signature generated: {signature_hash[:8]}... (URL: {signature_data.get('url', 'unknown')[:50]})")
        
        return signature_hash
        
    except Exception as e:
        logger.warning(f"Failed to get page signature: {e}")
        # è¿”å›åŸºäºæ—¶é—´å’ŒURLçš„å¤‡ç”¨ç­¾å
        try:
            current_url = await env.page.url if env.page else "unknown"
            fallback_string = f"{current_url}|{time.time()}"
            import hashlib
            return hashlib.md5(fallback_string.encode('utf-8')).hexdigest()
        except Exception:
            # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
            return str(time.time())


def is_repetitive_action(current_action, last_action, consecutive_count):
    """
    æ£€æµ‹æ˜¯å¦æ˜¯é‡å¤çš„æ— æ•ˆæ“ä½œ
    
    Args:
        current_action: å½“å‰æ“ä½œç±»å‹
        last_action: ä¸Šä¸€ä¸ªæ“ä½œç±»å‹
        consecutive_count: è¿ç»­ç›¸åŒæ“ä½œè®¡æ•°
        
    Returns:
        bool: æ˜¯å¦æ˜¯é‡å¤æ“ä½œ
    """
    # è¿ç»­ç›¸åŒçš„æ“ä½œç±»å‹
    if current_action == last_action:
        # æŸäº›æ“ä½œè¿ç»­æ‰§è¡Œå¯èƒ½æ˜¯æ­£å¸¸çš„ï¼ˆå¦‚æ»šåŠ¨æµè§ˆå†…å®¹ï¼‰
        if current_action in ["operator_scroll"]:
            return consecutive_count >= 2  # æ»šåŠ¨æ“ä½œå…è®¸2æ¬¡
        elif current_action in ["operator_click", "operator_type"]:
            return consecutive_count >= 1  # ç‚¹å‡»å’Œè¾“å…¥æ“ä½œä¸å…è®¸è¿ç»­
        elif current_action in ["operator_wait"]:
            return consecutive_count >= 0  # waitæ“ä½œç«‹å³è¢«è§†ä¸ºé‡å¤
        else:
            return consecutive_count >= 1
    
    return False


async def suggest_alternative_action(env, failed_action_type, task_name):
    """
    åŸºäºå¤±è´¥çš„æ“ä½œç±»å‹å’Œä»»åŠ¡å†…å®¹ï¼Œå»ºè®®æ›¿ä»£æ“ä½œ
    
    Args:
        env: ç¯å¢ƒå®ä¾‹
        failed_action_type: å¤±è´¥çš„æ“ä½œç±»å‹
        task_name: ä»»åŠ¡åç§°
        
    Returns:
        dict: å»ºè®®çš„æ›¿ä»£æ“ä½œï¼Œå¦‚æœæ²¡æœ‰å»ºè®®åˆ™è¿”å›None
    """
    try:
        page_info = await env.page.evaluate("""
            () => {
                // æ£€æŸ¥é¡µé¢ä¸Šçš„å¯äº¤äº’å…ƒç´ 
                const clickableElements = document.querySelectorAll('button, a, input[type="submit"], input[type="button"], [role="button"]');
                const inputElements = document.querySelectorAll('input[type="text"], input[type="search"], textarea');
                const scrollableElements = document.querySelectorAll('[style*="overflow"], .scroll, .scrollable');
                
                // æ£€æŸ¥æ˜¯å¦æœ‰æœç´¢ç›¸å…³å…ƒç´ 
                const searchElements = document.querySelectorAll('input[type="search"], input[placeholder*="search"], input[placeholder*="Search"], .search-input');
                
                // æ£€æŸ¥æ˜¯å¦æœ‰å¯¼èˆªå…ƒç´ 
                const navElements = document.querySelectorAll('nav, .nav, .navigation, .menu, [role="navigation"]');
                
                return {
                    hasClickableElements: clickableElements.length > 0,
                    hasInputElements: inputElements.length > 0,
                    hasSearchElements: searchElements.length > 0,
                    hasNavElements: navElements.length > 0,
                    clickableCount: clickableElements.length,
                    inputCount: inputElements.length,
                    currentUrl: window.location.href,
                    pageTitle: document.title
                };
            }
        """)
        
        # åŸºäºå¤±è´¥çš„æ“ä½œç±»å‹å’Œé¡µé¢çŠ¶æ€å»ºè®®æ›¿ä»£æ–¹æ¡ˆ
        if failed_action_type == "operator_scroll":
            # æ»šåŠ¨å¤±è´¥ï¼Œå°è¯•å…¶ä»–å¯¼èˆªæ–¹å¼
            if page_info["hasNavElements"]:
                return {
                    "action": "operator_click", 
                    "coordinates": [640, 100], # ç‚¹å‡»å¯¼èˆªåŒºåŸŸ
                    "action_input": "640,100",
                    "element_id": "nav_alternative"
                }
            elif page_info["hasClickableElements"]:
                return {
                    "action": "operator_click",
                    "coordinates": [640, 300], # ç‚¹å‡»é¡µé¢ä¸­éƒ¨
                    "action_input": "640,300", 
                    "element_id": "click_alternative"
                }
        
        elif failed_action_type == "operator_click":
            # ç‚¹å‡»å¤±è´¥ï¼Œå°è¯•æœç´¢æˆ–å…¶ä»–äº¤äº’
            if page_info["hasSearchElements"] and any(keyword in task_name.lower() for keyword in ["search", "find", "look"]):
                return {
                    "action": "operator_click",
                    "coordinates": [640, 200], # ç‚¹å‡»æœç´¢åŒºåŸŸ
                    "action_input": "640,200",
                    "element_id": "search_alternative"
                }
            else:
                # å°è¯•æŒ‰é”®æ“ä½œ
                return {
                    "action": "operator_keypress", 
                    "keys": ["Tab"],
                    "action_input": "Tab",
                    "element_id": "tab_alternative"
                }
        
        elif failed_action_type == "operator_type":
            # è¾“å…¥å¤±è´¥ï¼Œå°è¯•ç‚¹å‡»è¾“å…¥æ¡†æˆ–æ¸…ç©ºåé‡è¯•
            return {
                "action": "operator_keypress",
                "keys": ["Control", "a"], # å…¨é€‰
                "action_input": "Control,a",
                "element_id": "select_all_alternative"
            }
        
        # é€šç”¨å¤‡é€‰æ–¹æ¡ˆï¼šæŒ‰é”®æ“ä½œ
        return {
            "action": "operator_keypress",
            "keys": ["Escape"], # ESCé”®å¯èƒ½å…³é—­å¼¹çª—æˆ–é‡ç½®çŠ¶æ€
            "action_input": "Escape",
            "element_id": "escape_alternative"
        }
        
    except Exception as e:
        logger.warning(f"Failed to suggest alternative action: {e}")
        return None


async def run_experiment(task_range, experiment_config):
    for task_index in task_range:
        task_uuid = None
        if experiment_config.config['basic']['task_mode'] == "batch_tasks":
            task = experiment_config.file[task_index]
            task_name = task.get("confirmed_task", f"Task_{task_index}")
            task_uuid = task.get("task_id", f"task_{task_index}")
            reference_task_length = task.get("reference_length", 0)
            reference_evaluate_steps = task.get("evaluation", [])
            website = task.get("website", "about:blank")
            log_task_info(task_index, task_name,
                          reference_task_length, reference_evaluate_steps)
        elif experiment_config.config['basic']['task_mode'] == "single_task":
            task_name = experiment_config.single_task_name
            reference_task_length = experiment_config.config['steps']['single_task_action_step']
            reference_evaluate_steps = []
            website = experiment_config.config.get('single_task_website', "about:blank")
            task_uuid = f"single_task_{int(time.time())}"
            
            logger.info(f"task_name: {task_name}")
            logger.info(f"website: {website}")
            logger.info(f"mode: {experiment_config.mode}")

        # trajectory parameters
        screenshot_params = {
            "mode": experiment_config.mode,
            "record_time": experiment_config.record_time,
            "task_name": task_name,
            "task_name_id": task_uuid,
            "file_path": experiment_config.screenshot_base_dir or "results_operator"
        }
        
        # trajectory directory
        if experiment_config.screenshot_base_dir:
            base_screenshot_dir = os.path.join(experiment_config.screenshot_base_dir, "img_screenshots")
        else:
            base_screenshot_dir = os.path.join("results_operator", "img_screenshots")
        
        # trajectory directory
        safe_task_name = "".join(c for c in task_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
        safe_task_name = safe_task_name.replace(' ', '_')[:50]  # long name limit length to avoid path too long
        if not safe_task_name:
            safe_task_name = f"task_{task_uuid}"
        
        task_screenshot_dir = os.path.join(base_screenshot_dir, safe_task_name)
        if not os.path.exists(task_screenshot_dir):
            os.makedirs(task_screenshot_dir, exist_ok=True)
        
        # Operator mode uses special task running logic
        if experiment_config.mode == "operator":
            env = create_html_environment(experiment_config.mode, screenshot_dir=task_screenshot_dir)
            
            logger.info(f"ğŸ¤– Using OpenAI Operator mode")
            logger.info(f"ğŸ“± Planning model: {experiment_config.planning_text_model}")
            logger.info(f"ğŸ“¸ Screenshot support: Enabled")
            logger.info(f"ğŸ§  RAG support: {'Enabled' if experiment_config.rag_enabled else 'Disabled'}")
            
            await run_operator_task(
                env=env,
                task_name=task_name,
                task_uuid=task_uuid,
                website=website,
                config=experiment_config.config,
                planning_text_model=experiment_config.planning_text_model,
                record_time=experiment_config.record_time,
                write_result_file_path=experiment_config.write_result_file_path,
                reference_task_length=reference_task_length,
                reference_evaluate_steps=reference_evaluate_steps,
                screenshot_params=screenshot_params,
                rag_enabled=experiment_config.rag_enabled,
                rag_path=experiment_config.rag_path,
                global_reward_mode=experiment_config.global_reward_mode,
                global_reward_text_model=experiment_config.global_reward_text_model,
                ground_truth_mode=experiment_config.ground_truth_mode,
                ground_truth_data=experiment_config.ground_truth_data,
                rag_logging_enabled=experiment_config.rag_logging_enabled,
                rag_log_dir=experiment_config.rag_log_dir,
                rag_mode=experiment_config.rag_mode
            )
        else:
            # Other modes use the original logic
            env = create_html_environment(experiment_config.mode, screenshot_dir=task_screenshot_dir)
            
            await run_task(mode=experiment_config.mode,
                           task_mode=experiment_config.config['basic']['task_mode'],
                           task_name=task_name,
                           task_uuid=task_uuid,
                           config=experiment_config.config,
                           write_result_file_path=experiment_config.write_result_file_path,
                           reference_task_length=reference_task_length,
                           evaluate_steps=reference_evaluate_steps,
                           reference_evaluate_steps=reference_evaluate_steps,
                           env=env,
                           global_reward_mode=experiment_config.global_reward_mode,
                           global_reward_text_model=experiment_config.global_reward_text_model,
                           planning_text_model=experiment_config.planning_text_model,
                           ground_truth_mode=experiment_config.ground_truth_mode,
                           ground_truth_data=experiment_config.ground_truth_data,
                           interaction_mode=experiment_config.config['steps']['interaction_mode'],
                           task_index=task_index,
                           record_time=experiment_config.record_time,
                           token_pricing=experiment_config.config['token_pricing'],
                           screenshot_params=screenshot_params,
                           website=website,
                           rag_enabled=experiment_config.rag_enabled,
                           rag_path=experiment_config.rag_path
                           )
            
            await env.close()
            del env
        
    logger.info('\033[31mğŸ‰ All tasks finished!\033[0m')
    logger.info('\033[31mâ¸ï¸  Press Enter to exit...\033[0m')


async def main(global_reward_mode="no_global_reward",
               planning_text_model="computer-use-preview-2025-03-11",
               global_reward_text_model="gpt-4o-mini",
               single_task_name="",
               single_task_website="about:blank",
               raw_data_index=-1,
               observation_mode="operator",
               ground_truth_mode=False,
               toml_path=None,
               screenshot_base_dir=None,
               rag_logging_enabled=False,
               rag_log_dir=None,
               rag_mode="description"
               ):
    config = read_config(toml_path)
    config['single_task_website'] = single_task_website
    validate_config(config, observation_mode, global_reward_mode, planning_text_model, global_reward_text_model)

    file = None
    if config['basic']['task_mode'] == "batch_tasks":
        file = read_json_file(config['files']['batch_tasks_file_path'])
        task_range = get_task_range(
            config['basic']['task_mode'], file, raw_data_index)
    elif config['basic']['task_mode'] == "single_task":
        task_range = get_task_range(config['basic']['task_mode'], None, -1)

    record_time = time.strftime("%Y%m%d-%H%M%S", time.localtime())
    write_result_file_path = generate_result_file_path(config)
    ground_truth_data = load_ground_truth_data(config, ground_truth_mode)

    rag_enabled = config['rag']['enabled']
    rag_path = config['rag']['rag_path']

    # Set the RAG log directory
    if rag_log_dir is None:
        rag_log_dir = os.path.join(write_result_file_path, "rag_result")

    experiment_config = ExperimentConfig(
        mode=observation_mode,
        global_reward_mode=global_reward_mode,
        planning_text_model=planning_text_model,
        global_reward_text_model=global_reward_text_model,
        ground_truth_mode=ground_truth_mode,
        single_task_name=single_task_name,
        config=config,
        ground_truth_data=ground_truth_data,
        write_result_file_path=write_result_file_path,
        record_time=record_time,
        file=file,
        rag_enabled=rag_enabled,
        rag_path=rag_path,
        screenshot_base_dir=screenshot_base_dir,
        rag_logging_enabled=rag_logging_enabled,
        rag_log_dir=rag_log_dir,
        rag_mode=rag_mode
    )

    await run_experiment(task_range, experiment_config)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run the web agent with OpenAI Operator support.")
    parser.add_argument("--global_reward_mode",
                        choices=["dom_vision_reward", "dom_reward",
                                 "vision_reward", "no_global_reward"],
                        default="dom_reward", 
                        help="Choose the mode of global reward.")
    parser.add_argument("--index", type=str, default=-1)
    parser.add_argument("--single_task_name", type=str,
                        default="Find Dota 2 game and add all DLC to cart in steam.")
    parser.add_argument("--single_task_website", type=str,
                        default="about:blank", help="Website URL for single task mode")
    parser.add_argument("--snapshot", type=str, default="test/exp")
    parser.add_argument("--planning_text_model", type=str, default="computer-use-preview-2025-03-11")
    parser.add_argument("--global_reward_text_model", type=str, default="gpt-4o-mini")
    parser.add_argument("--observation_mode", type=str, default="operator",
                        choices=["dom", "operator", "vision", "dom_v_desc", "vision_to_dom", "d_v"],
                        help="Choose the observation mode")
    parser.add_argument("--ground_truth_mode", action="store_true", 
                        help="Enable ground truth mode")
    parser.add_argument("--toml_path", type=str, default=None,
                        help="Path to TOML configuration file")
    parser.add_argument("--screenshot_base_dir", type=str, default=None,
                        help="Base directory for screenshots")
    parser.add_argument("--rag_logging_enabled", action="store_true",
                        help="Enable RAG logging for operator mode")
    parser.add_argument("--rag_log_dir", type=str, default=None,
                        help="Directory to store RAG logs (default: results_dir/rag_result)")
    parser.add_argument("--rag_mode", type=str, default="description",
                        choices=["description", "vision"],
                        help="RAG mode: description (use text descriptions) or vision (use visual examples)")

    args = parser.parse_args()

    asyncio.run(main(global_reward_mode=args.global_reward_mode,
                     planning_text_model=args.planning_text_model,
                     global_reward_text_model=args.global_reward_text_model,
                     single_task_name=args.single_task_name,
                     single_task_website=args.single_task_website,
                     raw_data_index=args.index,
                     observation_mode=args.observation_mode,
                     ground_truth_mode=args.ground_truth_mode,
                     toml_path=args.toml_path,
                     screenshot_base_dir=args.screenshot_base_dir,
                     rag_logging_enabled=args.rag_logging_enabled,
                     rag_log_dir=args.rag_log_dir,
                     rag_mode=args.rag_mode
                     )
                ) 
