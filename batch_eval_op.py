"""
This is a batch test script specifically for OpenAI Operator mode.
This release adds the following features:
1. Support batch evaluation of OpenAI Operator mode (model :computer-use-preview-2025-03-11)
2. Support pure visual observation mode
3. Support RAG logging and custom storage paths

Usage:
    sudo yum install -y xorg-x11-server-Xvfb
    xvfb-run -a python batch_eval_op.py
    
    Ubuntu/Debian User:
    sudo apt-get update
    sudo apt-get install -y xvfb

    xvfb-run -a python batch_eval_op.py --global_reward_mode dom_reward --global_reward_text_model gpt-4.1 --snapshot test/exp --output_log test/exp/batch_operator_log.txt --rag_logging_enabled --rag_log_dir test/exp/rag_logs
"""

#!/usr/bin/env python3
import json
import os
import subprocess
import argparse
import time
from pathlib import Path

def load_tasks(json_path):
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

def run_single_operator_task(task, current_idx, args):
    task_name = task["confirmed_task"]
    website = task.get("website", "about:blank")
    task_id = task.get("task_id", f"task_{current_idx}")
    
    # eval_op.py params
    command = [
        "python", "eval_op.py",
        "--observation_mode", "operator",
        "--global_reward_mode", args.global_reward_mode,
        "--index", str(current_idx),
        "--single_task_name", task_name,
        "--single_task_website", website,
        "--snapshot", args.snapshot,
        "--planning_text_model", args.planning_text_model,
        "--global_reward_text_model", args.global_reward_text_model,
        "--screenshot_base_dir", args.snapshot
    ]
    
    if args.ground_truth_mode:
        command.append("--ground_truth_mode")
    
    if args.toml_path:
        command.extend(["--toml_path", args.toml_path])
    
    # RAG logging
    if args.rag_logging_enabled:
        command.append("--rag_logging_enabled")
    
    # RAG dir
    if args.rag_log_dir:
        command.extend(["--rag_log_dir", args.rag_log_dir])
    
    print(f"\n{'='*80}")
    print(f"ğŸ¤– Operatorä»»åŠ¡ [{current_idx}]: {task_name}")
    print(f"ğŸŒ ç½‘ç«™: {website}")
    print(f"ğŸ”§ ä»»åŠ¡ID: {task_id}")
    print(f"ğŸ“± æ¨¡å‹: {args.planning_text_model}")
    print(f"ğŸ“ RAGæ—¥å¿—: {'å¯ç”¨' if args.rag_logging_enabled else 'ç¦ç”¨'}")
    if args.rag_logging_enabled and args.rag_log_dir:
        print(f"ğŸ“‚ RAGæ—¥å¿—ç›®å½•: {args.rag_log_dir}")
    print(f"{'='*80}")
    
    try:
        # use headless mode
        if args.use_xvfb:
            full_command = ["xvfb-run", "-a"] + command
        else:
            full_command = command
            
        subprocess.run(full_command, check=True)
        print(f"âœ… ä»»åŠ¡å®Œæˆ: {task_name}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ ä»»åŠ¡å¤±è´¥: {task_name}")
        print(f"ğŸ”¥ é”™è¯¯: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='OpenAI Operator Mode Batch Evaluation')
    parser.add_argument('--json_path', type=str, default='data/Online-Mind2Web/72exp30.json',
                        help='JSONä»»åŠ¡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--global_reward_mode', type=str, default='dom_reward',
                        help='å…¨å±€å¥–åŠ±æ¨¡å¼: dom_reward/no_global_reward/dom_vision_reward')
    parser.add_argument('--index', type=int, default=-1,
                        help='ä»»åŠ¡ç´¢å¼•')
    parser.add_argument('--snapshot', type=str, default='test/exp',
                        help='æˆªå›¾ç›®å½•')
    parser.add_argument('--planning_text_model', type=str, default='computer-use-preview-2025-03-11',
                        help='è§„åˆ’æ–‡æœ¬æ¨¡å‹: computer-use-preview-2025-03-11/gpt-4.1')
    parser.add_argument('--global_reward_text_model', type=str, default='gpt-4.1',
                        help='å…¨å±€å¥–åŠ±æ–‡æœ¬æ¨¡å‹: gpt-4.1/gpt-4o-mini')
    parser.add_argument('--start_idx', type=int, default=0,
                        help='å¼€å§‹ä»»åŠ¡çš„ç´¢å¼•')
    parser.add_argument('--end_idx', type=int, default=None,
                        help='ç»“æŸä»»åŠ¡çš„ç´¢å¼•ï¼ˆä¸åŒ…å«ï¼‰')
    parser.add_argument('--delay', type=int, default=10,
                        help='ä»»åŠ¡é—´å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰')
    parser.add_argument('--output_log', type=str, default='test/exp/batch_operator_log.txt',
                        help='è¾“å‡ºæ—¥å¿—æ–‡ä»¶')
    parser.add_argument('--ground_truth_mode', action="store_true",
                        help='å¯ç”¨çœŸå®æ ‡å‡†æ¨¡å¼')
    parser.add_argument('--toml_path', type=str, default=None,
                        help='TOMLé…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--use_xvfb', action="store_true", default=True,
                        help='ä½¿ç”¨xvfbè¿è¡Œï¼ˆé»˜è®¤å¯ç”¨ï¼‰')
    parser.add_argument('--max_retries', type=int, default=2,
                        help='æ¯ä¸ªä»»åŠ¡çš„æœ€å¤§é‡è¯•æ¬¡æ•°')
    parser.add_argument('--rag_logging_enabled', action="store_true", default=False,
                        help='å¯ç”¨RAGæ—¥å¿—è®°å½•')
    parser.add_argument('--rag_log_dir', type=str, default=None,
                        help='RAGæ—¥å¿—æ–‡ä»¶çš„è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # load tasks
    json_path = Path(args.json_path)
    if not json_path.exists():
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {json_path}")
        return
    
    tasks = load_tasks(json_path)
    start_idx = args.start_idx
    end_idx = args.end_idx if args.end_idx is not None else len(tasks)
    
    total_tasks = end_idx - start_idx
    successful_tasks = 0
    failed_tasks = []
    
    os.makedirs(os.path.dirname(args.output_log), exist_ok=True)
    os.makedirs(args.snapshot, exist_ok=True)
    
    img_screenshots_dir = os.path.join(args.snapshot, "img_screenshots")
    logs_dir = os.path.join(args.snapshot, "logs")
    os.makedirs(img_screenshots_dir, exist_ok=True)
    os.makedirs(logs_dir, exist_ok=True)
    
    if args.output_log == 'results_operator/batch_exp1/logs/batch_operator_log.txt':
        args.output_log = os.path.join(logs_dir, 'batch_operator_log.txt')
    
    # init log file
    with open(args.output_log, 'w', encoding='utf-8') as log_file:
        log_file.write(f"ğŸš€ OpenAI Operatoræ‰¹é‡ä»»åŠ¡å¼€å§‹: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        log_file.write(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {total_tasks}\n")
        log_file.write(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {args.planning_text_model}\n")
        log_file.write(f"ğŸ“ ç»“æœç›®å½•: {args.snapshot}\n")
        log_file.write(f"ğŸ“¸ æˆªå›¾ç›®å½•: {img_screenshots_dir}\n")
        log_file.write(f"â±ï¸  ä»»åŠ¡é—´å»¶è¿Ÿ: {args.delay}ç§’\n")
        log_file.write(f"ğŸ”„ æœ€å¤§é‡è¯•æ¬¡æ•°: {args.max_retries}\n")
        log_file.write(f"ğŸ“ RAGæ—¥å¿—: {'å¯ç”¨' if args.rag_logging_enabled else 'ç¦ç”¨'}\n")
        if args.rag_logging_enabled and args.rag_log_dir:
            log_file.write(f"ğŸ“‚ RAGæ—¥å¿—ç›®å½•: {args.rag_log_dir}\n")
        log_file.write("\n")
    
    print(f"ğŸš€ å¼€å§‹OpenAI Operatoræ‰¹é‡ä»»åŠ¡è¯„ä¼°")
    print(f"ğŸ“Š ä»»åŠ¡èŒƒå›´: {start_idx} - {end_idx-1} (å…±{total_tasks}ä¸ªä»»åŠ¡)")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {args.planning_text_model}")
    print(f"ğŸ“ ç»“æœç›®å½•: {args.snapshot}")
    print(f"ğŸ“¸ æˆªå›¾ç›®å½•: {img_screenshots_dir}")
    
    for i, task_data in enumerate(tasks[start_idx:end_idx]):
        current_idx = start_idx + i
        task_name = task_data["confirmed_task"]
        website = task_data.get("website", "about:blank")
        task_id = task_data.get("task_id", f"task_{current_idx}")

        with open(args.output_log, 'a', encoding='utf-8') as log_file:
            log_file.write(f"ğŸ“‹ [{current_idx}/{len(tasks)}] è¿è¡Œä»»åŠ¡: {task_name}\n")
            log_file.write(f"ğŸŒ ç½‘ç«™: {website}\n")
            log_file.write(f"ğŸ”§ ä»»åŠ¡ID: {task_id}\n")
        
        # run task with retry
        success = False
        for attempt in range(args.max_retries + 1):
            if attempt > 0:
                print(f"ğŸ”„ é‡è¯•ç¬¬{attempt}æ¬¡: {task_name}")
                with open(args.output_log, 'a', encoding='utf-8') as log_file:
                    log_file.write(f"ğŸ”„ é‡è¯•ç¬¬{attempt}æ¬¡\n")
            
            success = run_single_operator_task(task_data, current_idx, args)
            if success:
                break
            elif attempt < args.max_retries:
                retry_delay = min(30, args.delay * 2)  # é‡è¯•æ—¶å¢åŠ å»¶è¿Ÿ
                print(f"â³ ç­‰å¾…{retry_delay}ç§’åé‡è¯•...")
                time.sleep(retry_delay)
        
        if success:
            successful_tasks += 1
            print(f"âœ… ä»»åŠ¡æˆåŠŸ: {task_name}")
        else:
            failed_tasks.append({
                "index": current_idx,
                "task_name": task_name,
                "task_id": task_id,
                "website": website
            })
            print(f"âŒ ä»»åŠ¡æœ€ç»ˆå¤±è´¥: {task_name}")
        
        with open(args.output_log, 'a', encoding='utf-8') as log_file:
            log_file.write(f"ğŸ“Š ç»“æœ: {'æˆåŠŸ' if success else 'å¤±è´¥'}\n")
            if not success:
                log_file.write(f"âŒ ç»è¿‡{args.max_retries}æ¬¡é‡è¯•åä»ç„¶å¤±è´¥\n")
            log_file.write("\n")
        
        # wait for next task
        if i < total_tasks - 1:
            print(f"â³ ç­‰å¾…{args.delay}ç§’åç»§ç»­ä¸‹ä¸€ä¸ªä»»åŠ¡...")
            time.sleep(args.delay)
    
    # final result
    success_rate = (successful_tasks / total_tasks * 100) if total_tasks > 0 else 0
    
    with open(args.output_log, 'a', encoding='utf-8') as log_file:
        log_file.write(f"\nğŸ å®Œæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        log_file.write(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {total_tasks}\n")
        log_file.write(f"âœ… æˆåŠŸä»»åŠ¡æ•°: {successful_tasks}\n")
        log_file.write(f"âŒ å¤±è´¥ä»»åŠ¡æ•°: {len(failed_tasks)}\n")
        log_file.write(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.2f}%\n")
        
        if failed_tasks:
            log_file.write(f"\nâŒ å¤±è´¥ä»»åŠ¡è¯¦æƒ…:\n")
            for failed_task in failed_tasks:
                log_file.write(f"  - [{failed_task['index']}] {failed_task['task_name']} ({failed_task['task_id']})\n")
                log_file.write(f"    ç½‘ç«™: {failed_task['website']}\n")
    
    print(f"\n{'='*80}")
    print(f"ğŸ OpenAI Operatoræ‰¹é‡ä»»åŠ¡è¯„ä¼°å®Œæˆ!")
    print(f"ğŸ“Š æ€»ä»»åŠ¡æ•°: {total_tasks}")
    print(f"âœ… æˆåŠŸä»»åŠ¡æ•°: {successful_tasks}")
    print(f"âŒ å¤±è´¥ä»»åŠ¡æ•°: {len(failed_tasks)}")
    print(f"ğŸ“ˆ æˆåŠŸç‡: {success_rate:.2f}%")
    print(f"ğŸ“ è¯¦ç»†æ—¥å¿—: {args.output_log}")
    
    if failed_tasks:
        print(f"\nâŒ å¤±è´¥çš„ä»»åŠ¡:")
        for failed_task in failed_tasks:
            print(f"  - [{failed_task['index']}] {failed_task['task_name']}")
    
    print(f"{'='*80}")

if __name__ == "__main__":
    main()